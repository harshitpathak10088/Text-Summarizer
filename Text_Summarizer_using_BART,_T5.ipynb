{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitpathak10088/Text-Summarizer/blob/main/Text_Summarizer_using_BART%2C_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csVpnsrMMWQd",
        "outputId": "06a3c18a-f4d1-4399-abe5-bd196b84945e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Preprocessed Text: natural language processing nlp field ai focus interaction human computer use language summarization important application nlp large text condense short meaningful version retain core information\n",
            "\n",
            "ðŸ“Œ Extractive Summary:\n",
            "Natural Language Processing (NLP) is a field of AI \n",
            "that focuses on the interaction between humans and computers using language. Summarization is an important application of NLP where large texts are \n",
            "condensed into shorter, meaningful versions while retaining core information.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Your max_length is set to 60, but your input_length is only 58. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Œ Abstractive Summary (BART):\n",
            "Natural Language Processing (NLP) is a field of AI that focuses on the interaction between humans and computers using language. Summarization is an important application of NLP where large texts are condensed into shorter, meaningful versions.\n",
            "\n",
            "ðŸ“Š ROUGE-1 Score: 0.27450980392156865\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score\n",
        "!pip install evaluate\n",
        "\n",
        "# ðŸ“Œ Text Summarization Project\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Import Required Libraries\n",
        "# ----------------------------\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Preprocessing Function\n",
        "# ----------------------------\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text:\n",
        "    - Lowercasing\n",
        "    - Stopword removal\n",
        "    - Lemmatization\n",
        "    \"\"\"\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [\n",
        "        token.lemma_ for token in doc\n",
        "        if token.is_alpha and token.text not in stopwords.words(\"english\")\n",
        "    ]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "sample_text = \"\"\"Natural Language Processing (NLP) is a field of AI\n",
        "that focuses on the interaction between humans and computers using language.\n",
        "Summarization is an important application of NLP where large texts are\n",
        "condensed into shorter, meaningful versions while retaining core information.\"\"\"\n",
        "\n",
        "clean_text = preprocess_text(sample_text)\n",
        "print(\"âœ… Preprocessed Text:\", clean_text)\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Extractive Summarization (Baseline)\n",
        "# ----------------------------\n",
        "def extractive_summary(text, num_sentences=2):\n",
        "    sentences = sent_tokenize(text)\n",
        "    return \" \".join(sentences[:num_sentences])  # simple: first N sentences\n",
        "\n",
        "print(\"\\nðŸ“Œ Extractive Summary:\")\n",
        "print(extractive_summary(sample_text))\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Abstractive Summarization (Transformers)\n",
        "# ----------------------------\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "generated_summary = summarizer(\n",
        "    sample_text,\n",
        "    max_length=60,\n",
        "    min_length=20,\n",
        "    do_sample=False\n",
        ")[0]['summary_text']\n",
        "\n",
        "print(\"\\nðŸ“Œ Abstractive Summary (BART):\")\n",
        "print(generated_summary)\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Evaluation (ROUGE-1 Score)\n",
        "# ----------------------------\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "reference = \"\"\"NLP enables communication between humans and computers.\n",
        "Summarization condenses long texts while keeping key information.\"\"\"\n",
        "\n",
        "scores = rouge.compute(predictions=[generated_summary], references=[reference])\n",
        "print(\"\\nðŸ“Š ROUGE-1 Score:\", scores[\"rouge1\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ðŸ“Œ Text Summarization Project (Clean + Fixed)\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Import Required Libraries\n",
        "# ----------------------------\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from transformers import pipeline\n",
        "import evaluate   # instead of datasets.load_metric\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Preprocessing Function\n",
        "# ----------------------------\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text:\n",
        "    - Lowercasing\n",
        "    - Stopword removal\n",
        "    - Lemmatization\n",
        "    \"\"\"\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [\n",
        "        token.lemma_ for token in doc\n",
        "        if token.is_alpha and token.text not in stopwords.words(\"english\")\n",
        "    ]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "sample_text = \"\"\"Natural Language Processing (NLP) is a field of AI\n",
        "that focuses on the interaction between humans and computers using language.\n",
        "Summarization is an important application of NLP where large texts are\n",
        "condensed into shorter, meaningful versions while retaining core information.\"\"\"\n",
        "\n",
        "clean_text = preprocess_text(sample_text)\n",
        "print(\"âœ… Preprocessed Text:\", clean_text)\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Extractive Summarization (Baseline)\n",
        "# ----------------------------\n",
        "def extractive_summary(text, num_sentences=2):\n",
        "    sentences = sent_tokenize(text)\n",
        "    return \" \".join(sentences[:num_sentences])  # simple: first N sentences\n",
        "\n",
        "print(\"\\nðŸ“Œ Extractive Summary:\")\n",
        "print(extractive_summary(sample_text))\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Abstractive Summarization (Transformers)\n",
        "# ----------------------------\n",
        "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
        "\n",
        "generated_summary = summarizer(\n",
        "    sample_text,\n",
        "    max_length=120,\n",
        "    min_length=40,\n",
        "    num_beams=6,\n",
        "    length_penalty=1.0,\n",
        "    early_stopping=True,\n",
        "    do_sample=False\n",
        ")[0]['summary_text']\n",
        "\n",
        "print(\"\\nðŸ“Œ Abstractive Summary (BART):\")\n",
        "print(generated_summary)\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Evaluation (ROUGE-1 Score)\n",
        "# ----------------------------\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "reference = \"\"\"NLP enables communication between humans and computers.\n",
        "Summarization condenses long texts while keeping key information.\"\"\"\n",
        "\n",
        "scores = rouge.compute(predictions=[generated_summary], references=[reference])\n",
        "print(\"\\nðŸ“Š ROUGE-1 Score:\", scores[\"rouge1\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmtjT3zUMZsp",
        "outputId": "b3b46052-25dc-4384-ec8f-66c9ebcbd39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Preprocessed Text: natural language processing nlp field ai focus interaction human computer use language summarization important application nlp large text condense short meaningful version retain core information\n",
            "\n",
            "ðŸ“Œ Extractive Summary:\n",
            "Natural Language Processing (NLP) is a field of AI \n",
            "that focuses on the interaction between humans and computers using language. Summarization is an important application of NLP where large texts are \n",
            "condensed into shorter, meaningful versions while retaining core information.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Your max_length is set to 120, but your input_length is only 57. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Œ Abstractive Summary (BART):\n",
            "natural language processing (NLP) is a field of AI that focuses on the interaction between humans and computers using language . large texts are condensed into shorter, meaningful versions while retaining core information .\n",
            "\n",
            "ðŸ“Š ROUGE-1 Score: 0.3404255319148936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CaVJCUx8Oo-j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}